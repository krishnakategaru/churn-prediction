{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xvX6CDcUplzV"
   },
   "source": [
    "#  Churn Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cg5sBJ1bpoDi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "0jBjr402pwSh",
    "outputId": "d807673d-6f49-4830-fc1c-69e06f18a5d8"
   },
   "outputs": [],
   "source": [
    "# Reading dataset\n",
    "telecom_df = pd.read_csv('telecom_churn_data.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "telecom_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "IgNtahFKqaWX",
    "outputId": "14df9172-910a-4f7c-d7d6-3131ef49b7fe"
   },
   "outputs": [],
   "source": [
    "# data check\n",
    "telecom_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "owsMK4MjrUSy",
    "outputId": "0baaae2c-2628-4fec-fbd4-42d9933c5e45"
   },
   "outputs": [],
   "source": [
    "telecom_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "DEFmVbjCsOpV",
    "outputId": "e8e9decd-1adf-4bef-9241-e2bf61724824"
   },
   "outputs": [],
   "source": [
    "telecom_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "3j7C6Udst4SC",
    "outputId": "d4f0f38f-df32-49f4-db2d-a337242b1e10"
   },
   "outputs": [],
   "source": [
    "# Finding missing value %\n",
    "100*telecom_df.isnull().sum()/len(telecom_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8E6bMDIlwXn5"
   },
   "outputs": [],
   "source": [
    "# # We can impute the missing values of below columns with zero\n",
    "\n",
    "telecom_df['total_rech_data_6'].fillna(0, inplace=True)\n",
    "telecom_df['total_rech_data_7'].fillna(0, inplace=True)\n",
    "telecom_df['total_rech_data_8'].fillna(0, inplace=True)\n",
    "telecom_df['total_rech_data_9'].fillna(0, inplace=True)\n",
    "\n",
    "telecom_df['av_rech_amt_data_6'].fillna(0, inplace=True)\n",
    "telecom_df['av_rech_amt_data_7'].fillna(0, inplace=True)\n",
    "telecom_df['av_rech_amt_data_8'].fillna(0, inplace=True)\n",
    "telecom_df['av_rech_amt_data_9'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YNf2hcFByAt8"
   },
   "outputs": [],
   "source": [
    "# Lets drop the columns which are having highest missing values and are not much useful\n",
    "\n",
    "telecom_df.drop('last_date_of_month_6', axis=1, inplace=True)\n",
    "telecom_df.drop('last_date_of_month_7', axis=1, inplace=True)\n",
    "telecom_df.drop('last_date_of_month_8', axis=1, inplace=True)\n",
    "t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since in the problem statement it was mentioned that we are not considering revenue based churn, we can drop below columns\n",
    "\n",
    "telecom_df.drop('arpu_2g_6', axis=1, inplace=True)\n",
    "telecom_df.drop('arpu_2g_7', axis=1, inplace=True)\n",
    "telecom_df.drop('arpu_2g_8', axis=1, inplace=True)\n",
    "telecom_df.drop('arpu_2g_9', axis=1, inplace=True)\n",
    "\n",
    "telecom_df.drop('arpu_3g_6', axis=1, inplace=True)\n",
    "telecom_df.drop('arpu_3g_7', axis=1, inplace=True)\n",
    "telecom_df.drop('arpu_3g_8', axis=1, inplace=True)\n",
    "telecom_df.drop('arpu_3g_9', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W2BhcgN9EHBb"
   },
   "outputs": [],
   "source": [
    "# We can just take a copy of the original dataset\n",
    "telecom_df_copy = telecom_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y7QQ0kvf0YPL"
   },
   "outputs": [],
   "source": [
    "# We can impute the missing values with either mean / median / Iterative Imputer. Let's try with II\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "telecom_columns = telecom_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "GUuf0B8UXN_i",
    "outputId": "e5701b97-dfbc-45c6-b76a-0faa741f38a2"
   },
   "outputs": [],
   "source": [
    "ii = IterativeImputer()\n",
    "telecom_df_clean = pd.DataFrame(ii.fit_transform(telecom_df_copy))\n",
    "telecom_df_clean.columns = telecom_columns\n",
    "telecom_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B81enNTdPZGP"
   },
   "outputs": [],
   "source": [
    "telecom_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SgPYp7kk02By"
   },
   "outputs": [],
   "source": [
    "telecom_df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YSoZbw2vfc4a"
   },
   "outputs": [],
   "source": [
    "# Lets check if the iterative imputer imputes any negative values in any non-negative columns\n",
    "\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.subplot(1,2,1)\n",
    "sns.boxplot(y=telecom_df.onnet_mou_6)\n",
    "plt.subplot(1,2,2)\n",
    "sns.boxplot(y=telecom_df_clean.onnet_mou_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OWwFU1iWO9CZ"
   },
   "source": [
    "##### If we closely observe, there are some negative values in minutes of usage which doesn't make any sense. So, let's delete those rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JagTSMRxPWpP"
   },
   "outputs": [],
   "source": [
    "# So, check for negative values created by iterative imputer and replace them with 0\n",
    "\n",
    "telecom_df_clean[telecom_df_clean < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4XqYgzIYQpXh"
   },
   "outputs": [],
   "source": [
    "telecom_df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i15aBLyofBH0"
   },
   "source": [
    "## Filter HVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cMqKJT8qfDL4"
   },
   "outputs": [],
   "source": [
    "# Highest Value Customers are those who are producing revenue who have recharged with an amount more than or equal to X, \n",
    "# where X is the 70th percentile of the average recharge amount in the first two months (the good phase).\n",
    "\n",
    "# To do that, we need to derive total amount of data recharge from the avg data amt recharge and total data recharges\n",
    "\n",
    "# Calculate call recharge + data recharge\n",
    "telecom_df_clean['total_amount_6'] = telecom_df_clean['total_rech_amt_6'] + (telecom_df_clean['av_rech_amt_data_6']*telecom_df_clean['total_rech_data_6'])\n",
    "telecom_df_clean['total_amount_7'] = telecom_df_clean['total_rech_amt_7'] + (telecom_df_clean['av_rech_amt_data_7']*telecom_df_clean['total_rech_data_7'])\n",
    "\n",
    "# Calculate the average recharge of June and July and also calculate the 70% of the value\n",
    "telecom_df_clean['average_rech_6_7'] = (telecom_df_clean['total_amount_6'] + telecom_df_clean['total_amount_7'])/2\n",
    "cut_off_hvc = telecom_df_clean['average_rech_6_7'].quantile(0.7)\n",
    "print(cut_off_hvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phRhIfrkgiIt"
   },
   "outputs": [],
   "source": [
    "# Now, filter out the High Value Customers from all customers and then will predict the churn for them\n",
    "\n",
    "telecom_df_hvc = telecom_df_clean[telecom_df_clean['average_rech_6_7'] >= cut_off_hvc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3pmEI-4Kyosi"
   },
   "outputs": [],
   "source": [
    "telecom_df_hvc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T5TLKhIJJ0Rv"
   },
   "source": [
    "## Deriving Churn column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QKbcUNhmzhEe"
   },
   "outputs": [],
   "source": [
    "telecom_df_hvc['total_ic_og_roam_mou_9'] = telecom_df_hvc['total_og_mou_9'] + telecom_df_hvc['total_ic_mou_9']\n",
    "telecom_df_hvc['total_data_vol_mb_9'] = telecom_df_hvc['vol_2g_mb_9'] + telecom_df_hvc['vol_3g_mb_9']\n",
    "\n",
    "telecom_df_hvc['Churn'] = np.where((telecom_df_hvc['total_ic_og_roam_mou_9'] + telecom_df_hvc['total_data_vol_mb_9']) <= 0 , 1 , 0)\n",
    "telecom_df_hvc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KsPcHjrW9Hj9"
   },
   "outputs": [],
   "source": [
    "telecom_df_hvc['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mE5360tS9M5N"
   },
   "outputs": [],
   "source": [
    "# Calculate churn percentage\n",
    "\n",
    "print(\"Churn percentage is: \",(telecom_df_hvc['Churn'].sum() / len(telecom_df_hvc))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g_VjbOviJ-qx"
   },
   "source": [
    "## Dropping 9th month data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ylRg5v9TCD3i"
   },
   "outputs": [],
   "source": [
    "# Take a copy and delete all 9th month data\n",
    "\n",
    "telecom_df_hvc_copy = telecom_df_hvc.copy()\n",
    "telecom_df_hvc = telecom_df_hvc.loc[:, ~telecom_df_hvc.columns.str.endswith('_9')]\n",
    "telecom_df_hvc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J6zEnFoHL5c4"
   },
   "outputs": [],
   "source": [
    "telecom_df_hvc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tj-VBsoLKJZP"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LbPlQVZBKOy5"
   },
   "outputs": [],
   "source": [
    "# Check for outliers in some continous variable columns\n",
    "\n",
    "telecom_df_hvc.describe(percentiles=[.25,.5,.75,.90,.95,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_EUE8QwYMDBK"
   },
   "outputs": [],
   "source": [
    "# From the above, we can clearly see there are outliers in almost all columns. Lets plot some and confirm\n",
    "\n",
    "plt.figure(figsize=[20,15])\n",
    "plt.subplot(3,3,1)\n",
    "sns.boxplot(y=telecom_df_hvc.arpu_6)\n",
    "plt.subplot(3,3,2)\n",
    "sns.boxplot(y=telecom_df_hvc.onnet_mou_6)\n",
    "plt.subplot(3,3,3)\n",
    "sns.boxplot(y=telecom_df_hvc.onnet_mou_6)\n",
    "plt.subplot(3,3,4)\n",
    "sns.boxplot(y=telecom_df_hvc.offnet_mou_6)\n",
    "plt.subplot(3,3,5)\n",
    "sns.boxplot(y=telecom_df_hvc.roam_ic_mou_6)\n",
    "plt.subplot(3,3,6)\n",
    "sns.boxplot(y=telecom_df_hvc.roam_og_mou_6)\n",
    "plt.subplot(3,3,7)\n",
    "sns.boxplot(y=telecom_df_hvc.total_og_mou_6)\n",
    "plt.subplot(3,3,8)\n",
    "sns.boxplot(y=telecom_df_hvc.total_ic_mou_6)\n",
    "plt.subplot(3,3,9)\n",
    "sns.boxplot(y=telecom_df_hvc.average_rech_6_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GVxAcf8_OzQb"
   },
   "outputs": [],
   "source": [
    "# We can either delete / treat / cap outliers based on our need. \n",
    "\n",
    "# Since, we have less data, we can now cap the outliers for all columns at once with below piece of code\n",
    "\n",
    "cols = telecom_df_hvc.columns\n",
    "# replacing the outliers with 99% value\n",
    "for col in cols[1:]:\n",
    "    Q3 = telecom_df_hvc[col].quantile(.99)\n",
    "    telecom_df_hvc[col] = telecom_df_hvc[col].replace(telecom_df_hvc[col][(telecom_df_hvc[col]>Q3)], Q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yr-z6IQuSEII"
   },
   "outputs": [],
   "source": [
    "# After capping outliers\n",
    "\n",
    "telecom_df_hvc.describe(percentiles=[.25,.5,.75,.90,.95,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AscH35VghcCx"
   },
   "outputs": [],
   "source": [
    "# Let's check the correlation coefficients to see which variables are highly correlated\n",
    "# For better visualization of heatmap we are dividing the dataframe into two keeping the dependent variable in common\n",
    "\n",
    "telecom_df_hvc_1 = telecom_df_hvc.iloc[:, :30]\n",
    "telecom_df_hvc_2 = telecom_df_hvc.iloc[:, 31:]\n",
    "telecom_df_hvc_1['Churn'] = telecom_df_hvc_2['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dg_juNHhiCtH"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25, 15))\n",
    "sns.heatmap(telecom_df_hvc_1.corr(), annot = True, cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z0jKEdOWlKuJ"
   },
   "source": [
    "##### From the above plot, we could see that total recharge amount and average revenue per user are highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I_52rYzqiIEX"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25, 15))\n",
    "sns.heatmap(telecom_df_hvc_2.corr(), annot = True, cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_lellVpDlkLf"
   },
   "source": [
    "###### From the above plot, Sachet and total recharge are highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ldf6A5NDTVQK"
   },
   "outputs": [],
   "source": [
    "# Train - Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y16yecFSWDMC"
   },
   "outputs": [],
   "source": [
    "# Take a copy before splitting\n",
    "telecom_df_hvc_split = telecom_df_hvc.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FnoWRR-WXZDp"
   },
   "outputs": [],
   "source": [
    "# Putting feature variable to X\n",
    "\n",
    "X = telecom_df_hvc.drop(['mobile_number','Churn'],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MfzO7aOdX8Kv"
   },
   "outputs": [],
   "source": [
    "# Putting response variable to y\n",
    "\n",
    "y = telecom_df_hvc['Churn']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LA3WFRx3YMxj"
   },
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TNCPc3NMJIVm"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE()\n",
    "X_smote,y_smote = sm.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-iXM4SGaJfP_"
   },
   "outputs": [],
   "source": [
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_smote, columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(y_smote, columns = ['Churn'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPqi2Ik8YSpE"
   },
   "outputs": [],
   "source": [
    "# Let's apply scaling on training data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for col in X.columns:\n",
    "    X_train[[col]] = scaler.fit_transform(X_train[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J4AZmC-uZbw2"
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8C-piZgMgYdN"
   },
   "source": [
    "### Feature Selection using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QqPRgno4aDQl"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7KgE0BI2de3Q"
   },
   "outputs": [],
   "source": [
    "# Running RFE with the output number of the variable equal to 15\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(logreg, 15)             # running RFE with 15 variables as output\n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CKgib-Vwgt3_"
   },
   "outputs": [],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3jgwaikogy0R"
   },
   "outputs": [],
   "source": [
    "list(zip(X_train.columns, rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFUHiELNg3KT"
   },
   "outputs": [],
   "source": [
    "colm = X_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "899HQJBYg-nQ"
   },
   "outputs": [],
   "source": [
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6EtVOBAbl6wg"
   },
   "source": [
    "###### Asseessing the model with statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3rQcHZ5Nl_Zd"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train[colm])\n",
    "logm1 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm1.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "77KWD8zxmncq"
   },
   "outputs": [],
   "source": [
    "# Checking VIF's\n",
    "\n",
    "# Check for the VIF values of the feature variables. \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GYbZmrxkoYyq"
   },
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[colm].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[colm].values, i) for i in range(X_train[colm].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rtveGhRQon2O"
   },
   "source": [
    "There are a few variables with high VIF. It's best to drop these variables as they aren't helping much with prediction and unnecessarily making the model complex. The variable 'total_og_mou_8' has the highest VIF. So let's start by dropping that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wfre7QyHofHn"
   },
   "outputs": [],
   "source": [
    "colm = colm.drop('total_og_mou_8', 1)\n",
    "colm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jHR-4qYpmMI"
   },
   "outputs": [],
   "source": [
    "# Let's re-run the model using the selected variables\n",
    "X_train_sm = sm.add_constant(X_train[colm])\n",
    "logm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logm2.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8ihqWUgyO28"
   },
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[colm].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[colm].values, i) for i in range(X_train[colm].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5mGz9soN8mm2"
   },
   "outputs": [],
   "source": [
    "# Getting the predicted values on the train set\n",
    "y_train_pred = res.predict(X_train_sm)\n",
    "y_train_pred = y_train_pred.values.reshape(-1)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m-aC5bRN81PB"
   },
   "outputs": [],
   "source": [
    "# y_train_pred_final = pd.DataFrame({'Churn':y_train.values, 'Churn_Prob':y_train_pred})\n",
    "y_train_pred_final = pd.DataFrame(y_train_pred, columns = ['Churn_Prob'])\n",
    "# y_train_pred_final = y_train_pred_final.rename(columns = {'0': 'Churn Prob'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['mbl_num'] = y_train.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final = pd.concat([y_train_pred_final, y_train], join = 'outer', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O70YEp_w9GRS"
   },
   "outputs": [],
   "source": [
    "y_train_pred_final['predicted'] = y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Let's see the head\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vN_vhbveyo4U"
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the confusion matrix again \n",
    "from sklearn import metrics\n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final.predicted )\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s6_a7Afv0DI4"
   },
   "outputs": [],
   "source": [
    "# Actual/Predicted     not_churn    churn\n",
    "        # not_churn        19138     171\n",
    "        # churn            1314      377  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG0VkM_n1QfF"
   },
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sxlbh43J1UuL"
   },
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m14_bcGe9j-U"
   },
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gH0lHHPi9m9d"
   },
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vfb-E2n59vkN"
   },
   "outputs": [],
   "source": [
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SB8vm8dC9yUW"
   },
   "outputs": [],
   "source": [
    "# positive predictive value \n",
    "print (TP / float(TP+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YA71pyEm91Gr"
   },
   "outputs": [],
   "source": [
    "# Negative predictive value\n",
    "print (TN / float(TN+ FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oku9DnVu-Ezy"
   },
   "source": [
    "### Plotting the ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2e1o1K5N944W"
   },
   "outputs": [],
   "source": [
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9AlMGPI-NRV"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Churn, y_train_pred_final.Churn_Prob, drop_intermediate = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "10FjzZsW-Sye"
   },
   "outputs": [],
   "source": [
    "draw_roc(y_train_pred_final.Churn, y_train_pred_final.Churn_Prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PSDzD4Bh-kzb"
   },
   "source": [
    "#### Finding Optimal Cutoff Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qsOuaST2-W6N"
   },
   "outputs": [],
   "source": [
    "# Optimal cutoff probability is that prob where we get balanced sensitivity and specificity\n",
    "\n",
    "# Let's create columns with different probability cutoffs \n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiicrCcg-vzO"
   },
   "outputs": [],
   "source": [
    "# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WYxvdrHI-2Cw"
   },
   "outputs": [],
   "source": [
    "# Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m78MSEE__E7k"
   },
   "source": [
    "#### From the curve above, 0.1 is the optimum point to take it as a cutoff probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5hgJFz74--5r"
   },
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Churn_Prob.map( lambda x: 1 if x > 0.55 else 0)\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hynwPz7i_MMq"
   },
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9t24TrIe_Qr9"
   },
   "outputs": [],
   "source": [
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final.final_predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cFCJYkwz_USt"
   },
   "outputs": [],
   "source": [
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7REgXW88_YBr"
   },
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHXskQ_D_Z7q"
   },
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rJ7beM_1_dHh"
   },
   "outputs": [],
   "source": [
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tjFX98Er_gop"
   },
   "outputs": [],
   "source": [
    "# Positive predictive value \n",
    "print (TP / float(TP+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hsFh3-h0_joS"
   },
   "outputs": [],
   "source": [
    "# Negative predictive value\n",
    "print (TN / float(TN+ FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n7nFQAV6_q2y"
   },
   "source": [
    "#### Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ebYUucDX_w5C"
   },
   "source": [
    "###### Precision\n",
    "###### TP / TP + FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkLXFVjs_ljV"
   },
   "outputs": [],
   "source": [
    "confusion[1,1]/(confusion[0,1]+confusion[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LnLNqv-8ABXW"
   },
   "source": [
    "###### Recall\n",
    "###### TP / TP + FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3VUSQKH3_7mm"
   },
   "outputs": [],
   "source": [
    "confusion[1,1]/(confusion[1,0]+confusion[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aKdAu9iqAH9A"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kN1wO9ngAUD0"
   },
   "outputs": [],
   "source": [
    "#?precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "63zwAkJOAVzJ"
   },
   "outputs": [],
   "source": [
    "precision_score(y_train_pred_final.Churn, y_train_pred_final.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3RkW1hJoAbIR"
   },
   "outputs": [],
   "source": [
    "recall_score(y_train_pred_final.Churn, y_train_pred_final.predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P9wYJ2hSAoXy"
   },
   "source": [
    "##### Precision and recall tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YOCRqBmnAc1_"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WJi8ryLkAsy4"
   },
   "outputs": [],
   "source": [
    "y_train_pred_final.Churn, y_train_pred_final.predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WC6lrq5lAwes"
   },
   "outputs": [],
   "source": [
    "p, r, thresholds = precision_recall_curve(y_train_pred_final.Churn, y_train_pred_final.Churn_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-DUO-f7eA0pI"
   },
   "outputs": [],
   "source": [
    "plt.plot(thresholds, p[:-1], \"g-\")\n",
    "plt.plot(thresholds, r[:-1], \"r-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xLo4ledA4Fo"
   },
   "outputs": [],
   "source": [
    "### Making predictions on the test set\n",
    "\n",
    "for c in colm:\n",
    "    X_test[[c]] = scaler.transform(X_test[[c]])\n",
    "X_test = X_test[colm]\n",
    "X_test_sm = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzxbYHO5BXoP"
   },
   "outputs": [],
   "source": [
    "y_test_pred = res.predict(X_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TC0HyKEYBdus"
   },
   "outputs": [],
   "source": [
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p4R0R0BrDcuY"
   },
   "outputs": [],
   "source": [
    "# Converting y_pred to a dataframe which is an array\n",
    "y_pred_1 = pd.DataFrame(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SfLY7BQBDstb"
   },
   "outputs": [],
   "source": [
    "# Let's see the head\n",
    "y_pred_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KFhRGdBeIEbG"
   },
   "outputs": [],
   "source": [
    "# Converting y_test to dataframe\n",
    "y_test_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1bG8S-N9MpEQ"
   },
   "outputs": [],
   "source": [
    "# Putting CustID to index\n",
    "y_test_df['mbl_num'] = y_test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nrwbXegxMtyQ"
   },
   "outputs": [],
   "source": [
    "# Removing index for both dataframes to append them side by side \n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAyxG_7GMyj_"
   },
   "outputs": [],
   "source": [
    "# Appending y_test_df and y_pred_1\n",
    "y_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PIudnu1eM47l"
   },
   "outputs": [],
   "source": [
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SIDU6BCgM7r4"
   },
   "outputs": [],
   "source": [
    "# Renaming the column \n",
    "y_pred_final= y_pred_final.rename(columns={ 0 : 'Churn_Prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_QPWrqrNEe_"
   },
   "outputs": [],
   "source": [
    "# Rearranging the columns\n",
    "y_pred_final = y_pred_final.reindex(['mbl_num','Churn','Churn_Prob'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R_7_JA1SNK7F"
   },
   "outputs": [],
   "source": [
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZxXPX8uNPjTI"
   },
   "outputs": [],
   "source": [
    "y_pred_final['final_predicted'] = y_pred_final.Churn_Prob.map(lambda x: 1 if x > 0.58 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wALWtiR9P4M1"
   },
   "outputs": [],
   "source": [
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NAyBjOFLP6_G"
   },
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "metrics.accuracy_score(y_pred_final.Churn, y_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3BmihsK1P_Kn"
   },
   "outputs": [],
   "source": [
    "confusion2 = metrics.confusion_matrix(y_pred_final.Churn, y_pred_final.final_predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwrFtCtZQCyz"
   },
   "outputs": [],
   "source": [
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7nVsw3vMQJS1"
   },
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cws5ajcgQNok"
   },
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3-wcZfGgTvnc"
   },
   "source": [
    "## Logistic Regression using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xT7do-NO_6F8"
   },
   "outputs": [],
   "source": [
    "# Putting feature variable to X\n",
    "\n",
    "X = telecom_df_hvc.drop(['mobile_number','Churn'],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y4MtBPNBAN7d"
   },
   "outputs": [],
   "source": [
    "# Putting response variable to y\n",
    "y = telecom_df_hvc['Churn']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nHHJTYoAAXg7"
   },
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7,test_size=0.3,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TNCPc3NMJIVm"
   },
   "outputs": [],
   "source": [
    "# getting rid of imbalancing using SMOTE\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE()\n",
    "X_train,y_train = sm.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-iXM4SGaJfP_"
   },
   "outputs": [],
   "source": [
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y8sZ1LWSdOEA"
   },
   "outputs": [],
   "source": [
    "# Import PCA module\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gpwL2uODeHs0"
   },
   "outputs": [],
   "source": [
    "# Create an instance of PCA\n",
    "pca = PCA(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x-XjbvYtfYmQ"
   },
   "outputs": [],
   "source": [
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TosXXHLPf66S"
   },
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AyLrCupBf-9r"
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nm331od1gBLg"
   },
   "outputs": [],
   "source": [
    "# Bar-plot explaining variance\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Bar-plot explaining variance')\n",
    "plt.xlabel('Number of componenets')\n",
    "plt.bar(range(1,len(pca.explained_variance_ratio_)+1), pca.explained_variance_ratio_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xs5M6QRHgFoN"
   },
   "outputs": [],
   "source": [
    "var_cumu = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EFGmtH9rgOKO"
   },
   "outputs": [],
   "source": [
    "# Scree plot\n",
    "fig = plt.figure(figsize=[12,8])\n",
    "plt.vlines(x=15, ymax=1, ymin=0, colors=\"r\", linestyles=\"--\")\n",
    "plt.hlines(y=0.95, xmax=30, xmin=0, colors=\"g\", linestyles=\"--\")\n",
    "plt.plot(var_cumu)\n",
    "plt.ylabel(\"Cumulative variance explained\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ClfnMEbEgr1q"
   },
   "source": [
    "From the above bar plot and Scree plot, we can say that the explained variance raitio is around 95% at 16 components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fM8np79lgRlu"
   },
   "outputs": [],
   "source": [
    "# Let's take n_components =16\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "pca_final = IncrementalPCA(n_components = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Yb2Oy2Vg2oz"
   },
   "outputs": [],
   "source": [
    "newdata = pca_final.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WtuiXnrEg560"
   },
   "outputs": [],
   "source": [
    "newdata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q14fQBZfhCl1"
   },
   "source": [
    "Making a dataframe out of it for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NoOIacWog8e7"
   },
   "outputs": [],
   "source": [
    "columns=[]\n",
    "for i in range(1,newdata.shape[1]+1):\n",
    "  columns.append(\"PC\"+str(i))\n",
    "pca_df = pd.DataFrame(newdata, columns=columns)\n",
    "pca_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uoL2unlwtD6X"
   },
   "outputs": [],
   "source": [
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EvD4WKaZhRYW"
   },
   "outputs": [],
   "source": [
    "corrmat = np.corrcoef(newdata.transpose())\n",
    "corrmat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XGDJMz0j99UQ"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,15])\n",
    "sns.heatmap(corrmat, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zaaWzOpbR_ye"
   },
   "outputs": [],
   "source": [
    "X_test_pca = pca_final.transform(X_test)\n",
    "X_test_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Qjt3koTSpaW"
   },
   "source": [
    "### Applying Logistic Regression on the data on our prinicipal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jGWIgrgbSWdN"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "learner_pca = LogisticRegression()\n",
    "model_pca = learner_pca.fit(newdata, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fGjakNJrTqOh"
   },
   "source": [
    "Making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fenO1zIqTDEa"
   },
   "outputs": [],
   "source": [
    "pred_probs_test = model_pca.predict_proba(X_test_pca)\n",
    "\"{:2.2}\".format(metrics.roc_auc_score(y_test, pred_probs_test[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qv1qPw_bT5S1"
   },
   "outputs": [],
   "source": [
    "pca_again = PCA(0.9)\n",
    "newdata2 = pca_again.fit_transform(X_train)\n",
    "newdata2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UPI1pFgkUOxB"
   },
   "outputs": [],
   "source": [
    "learner_pca2 = LogisticRegression()\n",
    "model_pca2 = learner_pca2.fit(newdata2, y_train)\n",
    "X_test_pca2 = pca_again.transform(X_test)\n",
    "X_test_pca2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQvwgUm2UdvK"
   },
   "outputs": [],
   "source": [
    "pred_probs_test2 = model_pca2.predict_proba(X_test_pca2)[:,1]\n",
    "\"{:2.2}\".format(metrics.roc_auc_score(y_test, pred_probs_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BQmW40RfeOuP"
   },
   "source": [
    "# Decision Tree using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XgWwWNjNprwr"
   },
   "outputs": [],
   "source": [
    "# Importing decision tree classifier from sklearn library\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Fitting the decision tree with default hyperparameters, apart from\n",
    "# max_depth which is 5 so that we can plot and read the tree.\n",
    "dt_default = DecisionTreeClassifier(max_depth=5)\n",
    "dt_default.fit(newdata, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cmIHQ-Xzpw4H"
   },
   "outputs": [],
   "source": [
    "# Let's check the evaluation metrics of our default model\n",
    "\n",
    "# Importing classification report and confusion matrix from sklearn metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Making predictions\n",
    "y_pred_default = dt_default.predict(X_test_pca)\n",
    "\n",
    "# Printing classification report\n",
    "print(classification_report(y_test, y_pred_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z9ExzG5QqRlE"
   },
   "outputs": [],
   "source": [
    "# Printing confusion matrix and accuracy\n",
    "confusion=confusion_matrix(y_test,y_pred_default)\n",
    "print(confusion)\n",
    "print(accuracy_score(y_test,y_pred_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mwNynQTt2oKU"
   },
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "enjJjeFH2oKh"
   },
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pgXp7kPY2oKo"
   },
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mgEZj2oEqb5U"
   },
   "source": [
    "### Plotting the Decision Tree\n",
    "\n",
    "We need the ```graphviz``` library to plot a tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ag9eLLr6qXWL"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Importing required packages for visualization\n",
    "from IPython.display import Image  \n",
    "from six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus, graphviz\n",
    "\n",
    "# Putting features\n",
    "features = list(pca_df.columns)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "44QUalLlq1JH"
   },
   "outputs": [],
   "source": [
    "# plotting tree with max_depth=3\n",
    "dot_data = StringIO()  \n",
    "export_graphviz(dt_default, out_file=dot_data,\n",
    "                feature_names=features, filled=True,rounded=True)\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rBA3-ElfrkoK"
   },
   "outputs": [],
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "### Tuning max_depth\n",
    "\n",
    "# GridSearchCV to find optimal max_depth\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_depth': range(1, 40)}\n",
    "\n",
    "# instantiate the model\n",
    "dtree = DecisionTreeClassifier(criterion = \"gini\", \n",
    "                               random_state = 100)\n",
    "\n",
    "# fit tree on training data\n",
    "tree = GridSearchCV(dtree, parameters, \n",
    "                    cv=n_folds,\n",
    "                    return_train_score='warn', \n",
    "                   scoring=\"accuracy\")\n",
    "tree.fit(newdata, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SUEZIBPIuVOg"
   },
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = tree.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CLtb0pdCvFmo"
   },
   "source": [
    "Now let's visualize how train and test score changes with max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kJd2na7ovBfs"
   },
   "outputs": [],
   "source": [
    "# plotting accuracies with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g7m71gQZwyFE"
   },
   "source": [
    "You can see that as we increase the value of max_depth, both training and test score increase till about max-depth = 4, after which the test score gradually reduces. Note that the scores are average accuracies across the 5-folds. \n",
    "\n",
    "Thus, it is clear that the model is overfitting the training data if the max_depth is too high. Next, let's see how the model behaves with other hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k2bYiyNHvKe-"
   },
   "outputs": [],
   "source": [
    "### Tuning min_samples_leaf\n",
    "\n",
    "# GridSearchCV to find optimal max_depth\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_leaf': range(5, 200, 20)}\n",
    "\n",
    "# instantiate the model\n",
    "dtree = DecisionTreeClassifier(criterion = \"gini\", \n",
    "                               random_state = 100)\n",
    "\n",
    "# fit tree on training data\n",
    "tree = GridSearchCV(dtree, parameters, \n",
    "                    cv=n_folds,\n",
    "                    return_train_score='warn', \n",
    "                   scoring=\"accuracy\")\n",
    "tree.fit(newdata, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yhDcXLkZw8Pk"
   },
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = tree.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zSIK9RGexYF_"
   },
   "outputs": [],
   "source": [
    "# plotting accuracies with min_samples_leaf\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_leaf\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zHVvbEItxqRg"
   },
   "source": [
    "You can see that at low values of min_samples_leaf, the tree gets a bit overfitted. At values > 100, however, the model becomes more stable and the training and test accuracy start to converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7HMRlShxdfH"
   },
   "outputs": [],
   "source": [
    "### Tuning min_samples_split\n",
    "\n",
    "# GridSearchCV to find optimal min_samples_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_split': range(5, 200, 20)}\n",
    "\n",
    "# instantiate the model\n",
    "dtree = DecisionTreeClassifier(criterion = \"gini\", \n",
    "                               random_state = 100)\n",
    "\n",
    "# fit tree on training data\n",
    "tree = GridSearchCV(dtree, parameters, \n",
    "                    cv=n_folds,\n",
    "                    return_train_score='warn', \n",
    "                   scoring=\"accuracy\")\n",
    "tree.fit(newdata, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEeUHXa6yBzs"
   },
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = tree.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QCaGZzZcyjrm"
   },
   "outputs": [],
   "source": [
    "# plotting accuracies with min_samples_leaf\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LxhVjWECyq9h"
   },
   "source": [
    "This shows that as you increase the min_samples_split, the tree overfits lesser since the model is less complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qGVt4ppDyw93"
   },
   "source": [
    "## Grid Search to Find Optimal Hyperparameters\n",
    "\n",
    "We can now use GridSearchCV to find multiple optimal hyperparameters together. Note that this time, we'll also specify the criterion (gini/entropy or IG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7shXw_Dym_m"
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid \n",
    "param_grid = {\n",
    "    'max_depth': range(5, 15, 5),\n",
    "    'min_samples_leaf': range(50, 150, 50),\n",
    "    'min_samples_split': range(50, 150, 50),\n",
    "    'criterion': [\"entropy\", \"gini\"]\n",
    "}\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "# Instantiate the grid search model\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid = param_grid, \n",
    "                          cv = n_folds, verbose = 1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(newdata,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DOsy-HBtzBkm"
   },
   "outputs": [],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "92L9w5SxzG5P"
   },
   "outputs": [],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "print(\"best accuracy\", grid_search.best_score_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gL--p0Y203cg"
   },
   "source": [
    "**Running the model with best parameters obtained from grid search.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBnrI9Ifz09H"
   },
   "outputs": [],
   "source": [
    "# model with optimal hyperparameters\n",
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
    "                                  random_state = 100,\n",
    "                                  max_depth=10, \n",
    "                                  min_samples_leaf=50,\n",
    "                                  min_samples_split=100)\n",
    "clf_gini.fit(newdata, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZmwlfHO91Cc4"
   },
   "outputs": [],
   "source": [
    "# accuracy score\n",
    "clf_gini.score(X_test_pca,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CjHlubQR1GHb"
   },
   "outputs": [],
   "source": [
    "\n",
    "dot_data = StringIO()  \n",
    "export_graphviz(clf_gini, out_file=dot_data,feature_names=features,filled=True,rounded=True)\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that this tree is too complex to understand. Let's try reducing the max_depth and see how the tree looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree with max_depth = 3\n",
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
    "                                  random_state = 100,\n",
    "                                  max_depth=3, \n",
    "                                  min_samples_leaf=50,\n",
    "                                  min_samples_split=100)\n",
    "clf_gini.fit(newdata, y_train)\n",
    "\n",
    "# score\n",
    "print(clf_gini.score(X_test_pca,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting tree with max_depth=3\n",
    "\n",
    "dot_data = StringIO()  \n",
    "export_graphviz(clf_gini, out_file=dot_data,feature_names=features,filled=True,rounded=True)\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "alx8YXJ11ZJZ"
   },
   "outputs": [],
   "source": [
    "# classification metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "y_pred = clf_gini.predict(X_test_pca)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WI6ocRu12C8"
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "confusion=confusion_matrix(y_test,y_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JgI0B_M93IwN"
   },
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fOMPqHCq3Iwo"
   },
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fZ8X60tc3Iwx"
   },
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "slEmFKvc5sQH"
   },
   "source": [
    "# Random Forest using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e7hb4_L57jC8"
   },
   "source": [
    "\n",
    "\n",
    "#### Default Hyperparameters\n",
    "Let's first fit a random forest model with default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mkUXfumF7SZf"
   },
   "outputs": [],
   "source": [
    "# Importing random forest classifier from sklearn library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Running the random forest with default parameters.\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9XbZEzv7n4F"
   },
   "outputs": [],
   "source": [
    "# fit\n",
    "rfc.fit(newdata,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHVSaGlU7s7n"
   },
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "predictions = rfc.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D9ENudCU7yo5"
   },
   "outputs": [],
   "source": [
    "# Importing classification report and confusion matrix from sklearn metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ASRvuMn8Aia"
   },
   "outputs": [],
   "source": [
    "# Let's check the report of our default model\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IF-gTRqu8iPh"
   },
   "outputs": [],
   "source": [
    "# Printing confusion matrix\n",
    "confusion=confusion_matrix(y_test,predictions)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GRFf-u438lXv"
   },
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mkToo6IP9l_m"
   },
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOnDuU1k9l_s"
   },
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d1UmECE29l_w"
   },
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2e4J3os92k7"
   },
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WWLbkgpo9yLJ"
   },
   "outputs": [],
   "source": [
    "### Tuning max_depth\n",
    "\n",
    "# GridSearchCV to find optimal n_estimators\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_depth': range(2, 20, 5)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds,\n",
    "                    return_train_score='warn', \n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(newdata, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a7YWrP6aAStZ"
   },
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s87HPnTIAiBY"
   },
   "outputs": [],
   "source": [
    "# plotting accuracies with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xCz-LC7nAyfF"
   },
   "source": [
    "You can see that as we increase the value of max_depth, both train and test scores increase till a point, but after that test score starts to decrease. The ensemble tries to overfit as we increase the max_depth.\n",
    "\n",
    "Thus, controlling the depth of the constituent trees will help reduce overfitting in the forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rapJcqQwAuZm"
   },
   "outputs": [],
   "source": [
    "### Tuning n_estimators\n",
    "\n",
    "# GridSearchCV to find optimal n_estimators\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'n_estimators': range(50, 500, 200)}\n",
    "\n",
    "# instantiate the model (note we are specifying a max_depth)\n",
    "rf = RandomForestClassifier(max_depth=4)\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                    return_train_score='warn',\n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(newdata, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YnWrL-MHA_Nn"
   },
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nA_iIbLPBEvE"
   },
   "outputs": [],
   "source": [
    "# plotting accuracies with n_estimators\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_n_estimators\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_n_estimators\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sGik78sTCfMX"
   },
   "outputs": [],
   "source": [
    "### Tuning max_features\n",
    "\n",
    "# Let's see how the model performance varies with ```max_features```, which is the maximum numbre of features considered for splitting at a node.\n",
    "\n",
    "# GridSearchCV to find optimal max_features\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_features': [0.2, 0.5, 0.75]}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(max_depth=4)\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   return_train_score='warn',\n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(newdata, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lzCMmd9JCsmi"
   },
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxQk0FmBCv0q"
   },
   "outputs": [],
   "source": [
    "# plotting accuracies with max_features\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_features\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_features\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_features\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z-0CwxOWDJON"
   },
   "source": [
    "Apparently, the training and test scores *both* seem to increase as we increase max_features, and the model doesn't seem to overfit more with increasing max_features. Think about why that might be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z1xQKQ9nDEmI"
   },
   "outputs": [],
   "source": [
    "### Tuning min_samples_leaf\n",
    "\n",
    "# GridSearchCV to find optimal min_samples_leaf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_leaf': range(100, 400, 50)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                  return_train_score='warn',\n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(newdata, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4-_w5WdhDU1P"
   },
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBxg_92CDYif"
   },
   "outputs": [],
   "source": [
    "# plotting accuracies with min_samples_leaf\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_leaf\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MF0MGI3hDhzi"
   },
   "source": [
    "You can see that the model starts of overfit as you decrease the value of min_samples_leaf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6e0ViW2kDk6V"
   },
   "outputs": [],
   "source": [
    "### Tuning min_samples_split\n",
    "\n",
    "# Let's now look at the performance of the ensemble as we vary min_samples_split.\n",
    "\n",
    "# GridSearchCV to find optimal min_samples_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_split': range(200, 500, 50)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds,\n",
    "                    return_train_score='warn',\n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(newdata, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kxp2ZNwgECMv"
   },
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_UuXZz55EIM8"
   },
   "outputs": [],
   "source": [
    "# plotting accuracies with min_samples_split\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6NXfIKj4Ec-v"
   },
   "source": [
    "## Grid Search to Find Optimal Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HvDHr_OIEdm_"
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [4,8,10],\n",
    "    'min_samples_leaf': range(100, 400, 200),\n",
    "    'min_samples_split': range(200, 500, 200),\n",
    "    'n_estimators': [100,200, 300], \n",
    "    'max_features': [5, 10]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sFRaxDEzFJgC"
   },
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(newdata, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SBS27nm2FPD-"
   },
   "outputs": [],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "print('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations and recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After using the RFE in Logistic regression without using PCA the top variables are\n",
    "\n",
    "total_ic_mou_8\n",
    "total_rech_num_8\n",
    "total_ic_mou_7\n",
    "total_rech_num_7\n",
    "arpu_7\n",
    "offnet_mou_8\n",
    "sachet_2g_8\n",
    "last_day_rch_amt_8\n",
    "onnet_mou_8\n",
    "vol_2g_mb_8\n",
    "roam_og_mou_8\n",
    "monthly_2g_8\n",
    "monthly_3g_8\n",
    "sep_vbc_3g\n",
    "\n",
    "##### After using the Logistic regression on PCA variables we got the roc_auc_score = 0.86.\n",
    "\n",
    "##### After building the model using Decision tree with best parameters obtained from grid search we got\n",
    "    Accuracy = 0.802 with depth = 10\n",
    "    Accuracy = 0.72, specificity = 0.73 with depth = 3\n",
    "After building the model using Random forest on PCA variables we got the accuracy as 0.83\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of Telecom Churn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
